Building a Prediction Model to Predict Activity Quality 
========================================================
R Packages in need
------------------
```{r,warning=FALSE}
library(caret)
library(ggplot2)
library(randomForest)
library(e1071)
```

Data
----
We collected our data from https://class.coursera.org/predmachlearn-004/human_grading/view/courses/972149/assessments/4/submissions and downloaded them from the following 2 links:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

We will focus entirely on training set(i will refer to it as data) and ignore testing set till the very end.

At first look, the data includes 160 variables , in which only 53 are considered important features.
The rest were either mostly empty, NA or irrelevant as they indicate the time, the name of the person or just a row-counting number.

```{r,echo=TRUE}
data<-read.csv("pml-training.csv",colClasses=c(
  rep("NULL",7) ,rep(NA,4), ##11
  rep("NULL",25),rep(NA,13),##49
  rep("NULL",10),rep(NA,9),##68
  rep("NULL",15),rep(NA,3),##86
  rep("NULL",15),NA,##102
  rep("NULL",10),rep(NA,12),##124
  rep("NULL",15),NA,##140
  rep("NULL",10),rep(NA,10)##160
  ))
testdata<-read.csv("pml-testing.csv",colClasses=c(
  rep("NULL",7) ,rep(NA,4), ##11
  rep("NULL",25),rep(NA,13),##49
  rep("NULL",10),rep(NA,9),##68
  rep("NULL",15),rep(NA,3),##86
  rep("NULL",15),NA,##102
  rep("NULL",10),rep(NA,12),##124
  rep("NULL",15),NA,##140
  rep("NULL",10),rep(NA,10)##160
))
```

Creating the Prediction Model
-----------------------------
I consider the sample has medium size, therefore i subsplit it into 60% training set and 40% testing set.

I use seeds so i make sure my research is reproducible.

```{r,echo=TRUE}
set.seed(13234)
inTrain=createDataPartition(data$classe,p=0.6,list=F)
training=data[inTrain,]
testing=data[-inTrain,]
```

From all the prediction models, i have chosen random Forest. It has the best accuracy from the models, i have
tested so far, and since our data does not have large sample size , speed is not a hindrance.

```{r,echo=TRUE}
modFit<-randomForest(classe~.,data=training)
```

Here we take a look at our model.

```{r,echo=TRUE}
modFit
```

To check the accuracy we take the summation of the numerical values on the diagonal over the total
amount of numerical values of our data. OR we just subract the "OOB estimate of error rate from 1".
In other words:
```{r,echo=TRUE}
DiagonicalValues<-3342+2258+2035+1905+2160
TrainingAccuracy<-DiagonicalValues/(DiagonicalValues+15+5+16+1+6+23+1+3+4+2)
TrainingAccuracy
1-0.65*0.01
```

Results on Training Set
--------
We use the following commands to check our Prediction Model on testing set and take a look at "new data"'s accuracy .

```{r,echo=TRUE}
pred<-predict(modFit,testing)
confusionMatrix(pred,testing$classe)
```

Accuracy: 0.992 is a nice one and also our Out of Sample Error is 0.8%. Therefore,since we have only 0.8% error rate for our predictions, we can now test our model to the real testing set.
Results on Real Training Set
----------------------------

```{r,echo=TRUE}
answers<-predict(modFit,testdata)
answers<-as.character(answers)
answers
```

